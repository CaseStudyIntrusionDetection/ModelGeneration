# Settings

- `pipeline_active` *object* De-/ activate parts of pipeline 
	- `dataset` *bool* Convert the snare logs to LDA like texts and corpus
	- `features` *bool* Build the dictionary for LDA
	- `train` *bool* Learn the model and supervised learn distribution for attack, benign, emulator, zap-id 
	- `predict` *bool* Use the test set and predict all requests, write report and precision, recall
	- `visualize` *bool* Better visualization of learned topics and features
	- `visualize_dataset` *bool* Visualization of corpus used for training and testing
- `training_data` *array of objects* Each object defines one input file from snare (train set)
	- `name` *string* A name for the file (used in output later)
	- `file` *string* The path to the logfile (`*.json`)
	- `type` *string* The type of the data (`"benign"` or `"attack"`)
	- `filter` *lambda* A lambda expression to filter data (optional, if not defined, all data will be chosen), e.g. `r['honeypot']['used-emulator'] == 'rfi'` or `int(r['zap-id']) > 20`
- `test_data` *array of objects* Each object defines one input file from snare (test set)
	- Keys like `training_data`
- `corpus` *object* Parameter used in corpus generation
	- `document_per_request` *bool* If true, we create one document for each request (cannot be true if `document_per_connection_id` is true)
	- `document_per_connection_id` *bool* If true, we create one document for each connection (cannot be true if `document_per_request` is true)
	- `document_request_window_size` *int* If `document_per_request` and `document_per_connection_id` are false, we create one document for each group of requests with the given window size from the same connection
	- `output_document_topics` *bool* Also log the topics per document in the logfiles (results in huge files)
	- `use_times` *bool* Use timestamps in the corpora (may result in false results, cause the model will learn the times of attacks and benign requests)
- `output`
	- `dir` *string* The directory for all output files generated by the pipeline (corpus, model, trained data, report)
	- `name` *string* The prefix for the filenames of all output files generated by the pipeline
- `lda` *object* Parameter used while learning model
	- `topics` *int* Parameter used to specify how many topics the model should have
	- `max_iteration` *int* Parameter used to specify how many iterations OLDA will do maximally
	- `alpha` *real* Parameter for document topic distribution
	- `beta` *real* Parameter for word topic distribution
	- `min_probability` *real* Topics featuring a smaller probability will be ignored by gensim
	- `gamma_threshold` *real* Minimal changes of gamma to keep OLDA iterating
	- `min_phi_value` *real* Word featuring a smaller probability will not be shown in topics
- `predict` *object* Parameter used in the prediction step
	- `use_olda` *bool* If true, OLDA should be used, else FIGS
	- `incrementally_learn_olda_model` *bool* Specifies if OLDA should be used initially or incrementally [^1]
	- `only_zap-id_is_attack` *bool* If true, only requests with a set zap-id are considered as an attack else all request from a file with type `"type"=="attack"`
